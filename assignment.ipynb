{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q5_ZymVlv_w",
        "outputId": "5e266b93-c4a8-4154-cd08-206c0de65462"
      },
      "id": "2Q5_ZymVlv_w",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy tqdm fuzzywuzzy openai"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GXrmtEVmd16",
        "outputId": "e23d1bdd-3d70-408c-bdce-14a2696a3ada"
      },
      "id": "9GXrmtEVmd16",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd 'MyDrive/Bankers_Network/LinkedIn profiling'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMzSgPKem1m2",
        "outputId": "88ac6a38-a820-48cc-f21f-481af3a810d6"
      },
      "id": "jMzSgPKem1m2",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1-TcZn4rKuA_sOdUdtDa6_tBq8jBjFBt_/Bankers_Network/LinkedIn profiling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igpDHmkPnW1Q",
        "outputId": "509e8df5-bba9-4a8f-9899-5b4e3519a3df"
      },
      "id": "igpDHmkPnW1Q",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assembling_data.do  degree.docx   gpt_education.py  \u001b[0m\u001b[01;34mR\u001b[0m/\n",
            "bankerdeal_vars.do  education.py  gpt_jobs.py       z_check.do\n",
            "dataset_cleaner.py  genderize.py  jobs.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking *`dataset_cleaner.py`* ---> Reproducibility: **0/10** draws data from a missing directory"
      ],
      "metadata": {
        "id": "TvLuEbd1oXjB"
      },
      "id": "TvLuEbd1oXjB"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import chardet\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "Qo9niTkYnZmT"
      },
      "id": "Qo9niTkYnZmT",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Will not work --> private dropbox\n",
        "db='C:/Users/jacop/Dropbox'\n",
        "outpath=db+'/LinkedIn profiling/'"
      ],
      "metadata": {
        "id": "4mv1ss_hpDqS"
      },
      "id": "4mv1ss_hpDqS",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders_list=[]\n",
        "info_general= pd.DataFrame()\n",
        "jobs = pd.DataFrame()\n",
        "education = pd.DataFrame()\n",
        "skills = pd.DataFrame()\n",
        "interests = pd.DataFrame()"
      ],
      "metadata": {
        "id": "Vavpm7okpI75"
      },
      "id": "Vavpm7okpI75",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Will not work --> where is this dir.\n",
        "parent_directory=db+'/AdditionalCollection'\n",
        "for item in os.listdir(parent_directory):\n",
        "    if os.path.isdir(os.path.join(parent_directory, item)):\n",
        "      folders_list.append(item)"
      ],
      "metadata": {
        "id": "YfT57SUBpQo7"
      },
      "id": "YfT57SUBpQo7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Won't work --> same thing, no parent directory present\n",
        "j=5\n",
        "\n",
        "directory=parent_directory+\"/\"+folders_list[j]+\"/unzipped\"\n",
        "extraction=parent_directory+\"/\"+folders_list[j]+\"/extracted\"\n",
        "for item in os.listdir(directory):\n",
        "    subdirectory=directory+\"/\"+item\n",
        "\n",
        "    for item in os.listdir(subdirectory):\n",
        "        json_file = [f for f in os.listdir(subdirectory) if os.path.isfile(os.path.join(subdirectory, f)) and f.endswith('.json')]\n",
        "\n",
        "\n",
        "    f=subdirectory+\"/\"+json_file[0]\n",
        "    with open(f, encoding='utf-8') as f:\n",
        "        data=json.load(f)\n",
        "    error_records=0\n",
        "\n",
        "    for rec in tqdm(range(0,len(data))):\n",
        "\n",
        "        records=list(data[rec])\n",
        "\n",
        "        if 'error' in records:\n",
        "            error_records=error_records+1\n",
        "        else:\n",
        "\n",
        "            if 'general' in records:\n",
        "                info_general_r=pd.DataFrame.from_dict([data[rec]['general']])\n",
        "                info_general_r.rename(columns = {'profileUrl':'url'}, inplace = True)\n",
        "            else:\n",
        "              info_general_r=pd.DataFrame()\n",
        "\n",
        "\n",
        "            jobs_r = pd.DataFrame()\n",
        "            if 'jobs' in records:\n",
        "                for x in range(0,len(data[rec]['jobs'])):\n",
        "                    rowjob=pd.DataFrame.from_dict([data[rec]['jobs'][x]])\n",
        "                    jobs_r = pd.concat([jobs_r, rowjob.loc[:]]).reset_index(drop=True)\n",
        "                try:\n",
        "                    jobs_r['url']=data[rec]['general']['profileUrl']\n",
        "                except:\n",
        "                    jobs_r['url']=data[rec]['query']\n",
        "\n",
        "            education_r = pd.DataFrame()\n",
        "            if 'schools' in records:\n",
        "                for x in range(0,len(data[rec]['schools'])):\n",
        "                    rowschool=pd.DataFrame.from_dict([data[rec]['schools'][x]])\n",
        "                    education_r = pd.concat([education_r, rowschool.loc[:]]).reset_index(drop=True)\n",
        "                    education_r['url']=data[rec]['general']['profileUrl']\n",
        "\n",
        "            skills_r = pd.DataFrame(columns=['name', 'endorsements'])\n",
        "            if 'skills' in records:\n",
        "                for x in range(0,len(data[rec]['skills'])):\n",
        "                    rowskill=pd.DataFrame.from_dict([data[rec]['skills'][x]])\n",
        "                    skills_r = pd.concat([skills_r, rowskill.loc[:]]).reset_index(drop=True)\n",
        "                    skills_r['url']=data[rec]['general']['profileUrl']\n",
        "\n",
        "            interests_r = pd.DataFrame()\n",
        "            if 'interests' in records:\n",
        "                interest_cat=list(data[rec]['interests'])\n",
        "                for c in interest_cat:\n",
        "                    interests_c = pd.DataFrame()\n",
        "                    for x in range(0,len(data[rec]['interests'][c])):\n",
        "                        rowinterest=pd.DataFrame.from_dict([data[rec]['interests'][c][x]])\n",
        "                        interests_c = pd.concat([interests_c, rowinterest.loc[:]]).reset_index(drop=True)\n",
        "                        interests_c['category']=c\n",
        "                    interests_r = pd.concat([interests_r, interests_c.loc[:]]).reset_index(drop=True)\n",
        "                    interests_r['url']=data[rec]['general']['profileUrl']\n",
        "\n",
        "            info_general = pd.concat([info_general, info_general_r.loc[:]]).reset_index(drop=True)\n",
        "            jobs = pd.concat([jobs, jobs_r.loc[:]]).reset_index(drop=True)\n",
        "            education = pd.concat([education, education_r.loc[:]]).reset_index(drop=True)\n",
        "            skills = pd.concat([skills, skills_r.loc[:]]).reset_index(drop=True)\n",
        "            interests = pd.concat([interests, interests_r.loc[:]]).reset_index(drop=True)\n",
        "\n",
        "info_general.to_csv(extraction+'/info_general.csv',encoding='utf-8-sig')\n",
        "jobs.to_csv(extraction+'/jobs.csv',encoding='utf-8-sig')\n",
        "education.to_csv(extraction+'/education.csv',encoding='utf-8-sig')\n",
        "skills.to_csv(extraction+'/skills.csv',encoding='utf-8-sig')\n",
        "interests.to_csv(extraction+'/interests.csv',encoding='utf-8-sig')\n",
        "\n",
        "\n",
        "f=\"C:/Users/jacop/Dropbox/AdditionalCollection/5_Collection_Erica_Done/unzipped/_1/result.json\"  # Test file\n",
        "\n",
        "\n",
        "with open(f, encoding='utf-8') as f:\n",
        "    data=json.load(f)\n",
        "\n",
        "error_records=0\n",
        "\n",
        "for rec in tqdm(range(0,len(data))):\n",
        "\n",
        "    records=list(data[rec])\n",
        "\n",
        "    if 'error' in records:\n",
        "        error_records=error_records+1\n",
        "    else:\n",
        "\n",
        "        if 'general' in records:\n",
        "            info_general_r=pd.DataFrame.from_dict([data[rec]['general']])\n",
        "            info_general_r.rename(columns = {'profileUrl':'url'}, inplace = True)\n",
        "        else:\n",
        "          info_general_r=pd.DataFrame()\n",
        "\n",
        "        jobs_r = pd.DataFrame()\n",
        "        if 'jobs' in records:\n",
        "            for x in range(0,len(data[rec]['jobs'])):\n",
        "                rowjob=pd.DataFrame.from_dict([data[rec]['jobs'][x]])\n",
        "                jobs_r = pd.concat([jobs_r, rowjob.loc[:]]).reset_index(drop=True)\n",
        "            jobs_r['url']=data[rec]['general']['profileUrl']\n",
        "\n",
        "        education_r = pd.DataFrame()\n",
        "        if 'schools' in records:\n",
        "            for x in range(0,len(data[rec]['schools'])):\n",
        "                rowschool=pd.DataFrame.from_dict([data[rec]['schools'][x]])\n",
        "                education_r = pd.concat([education_r, rowschool.loc[:]]).reset_index(drop=True)\n",
        "                education_r['url']=data[rec]['general']['profileUrl']\n",
        "\n",
        "        skills_r = pd.DataFrame(columns=['name', 'endorsements'])\n",
        "        if 'skills' in records:\n",
        "            for x in range(0,len(data[rec]['skills'])):\n",
        "                rowskill=pd.DataFrame.from_dict([data[rec]['skills'][x]])\n",
        "                skills_r = pd.concat([skills_r, rowskill.loc[:]]).reset_index(drop=True)\n",
        "                skills_r['url']=data[rec]['general']['profileUrl']\n",
        "\n",
        "        interests_r = pd.DataFrame()\n",
        "        if 'interests' in records:\n",
        "            interest_cat=list(data[rec]['interests'])\n",
        "            for c in interest_cat:\n",
        "                interests_c = pd.DataFrame()\n",
        "                for x in range(0,len(data[rec]['interests'][c])):\n",
        "                    rowinterest=pd.DataFrame.from_dict([data[rec]['interests'][c][x]])\n",
        "                    interests_c = pd.concat([interests_c, rowinterest.loc[:]]).reset_index(drop=True)\n",
        "                    interests_c['category']=c\n",
        "                interests_r = pd.concat([interests_r, interests_c.loc[:]]).reset_index(drop=True)\n",
        "                interests_r['url']=data[rec]['general']['profileUrl']\n",
        "\n",
        "        info_general = pd.concat([info_general, info_general_r.loc[:]]).reset_index(drop=True)\n",
        "        jobs = pd.concat([jobs, jobs_r.loc[:]]).reset_index(drop=True)\n",
        "        education = pd.concat([education, education_r.loc[:]]).reset_index(drop=True)\n",
        "        skills = pd.concat([skills, skills_r.loc[:]]).reset_index(drop=True)\n",
        "        interests = pd.concat([interests, interests_r.loc[:]]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "Aoiic15qprQt"
      },
      "id": "Aoiic15qprQt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def clean_json(f, data, info_general, jobs,education,skills,interests):\n",
        "#        return info_general, jobs, education, skills, interests\n",
        "#clean_json(f, data,info_general, jobs,education,skills,interests)\n",
        "# What does this do? Takes test filename its data and returns the other arguments, starting to suspect that this is not a final notebook, more an index-v0"
      ],
      "metadata": {
        "id": "LoZdzXrnqT8d"
      },
      "id": "LoZdzXrnqT8d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export tables to CSV --> not runnable since the actual objects are empty\n",
        "info_general.to_csv(outpath+'info_general.csv',encoding='utf-8-sig')\n",
        "jobs.to_csv(outpath+'jobs.csv',encoding='utf-8-sig')\n",
        "education.to_csv(outpath+'education.csv',encoding='utf-8-sig')\n",
        "skills.to_csv(outpath+'skills.csv',encoding='utf-8-sig')\n",
        "interests.to_csv(outpath+'interests.csv',encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "rVpkai4Aq527"
      },
      "id": "rVpkai4Aq527",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking `education.py` ---> Reproducibility: **6/10** needs adjustments, but ca be reproduced"
      ],
      "metadata": {
        "id": "R0uRRB7Krrf5"
      },
      "id": "R0uRRB7Krrf5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up your DB path\n",
        "db='C:/Users/jacop/Dropbox' # --> remove\n",
        "\n",
        "# Set up input folder\n",
        "path=db+'/LinkedIn profiling/clean/' # --> becomes: path = './clean'  (since parent dir is supposed to be LinkedIn profiling)\n",
        "\n",
        "# Set up output folder\n",
        "output=db+'/LinkedIn profiling/clean/fuzzy/' # --> similarly becomes output = './clean/fuzzy'\n",
        "\n",
        "# This part needs only this adjustment in order to be reproducible, done as major part with regex, reproducible but not scalable. (transformer cleaning?)\n",
        "# Also this .py seems to be a non-final version, has redundancy and newer/improved methods inside"
      ],
      "metadata": {
        "id": "oRcAmyz2ros4"
      },
      "id": "oRcAmyz2ros4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.set_index('schoolname', inplace=True)\n",
        "data.set_index('schoolname', inplace=True)\n",
        "# = pd.concat([df, data], axis=1) --> missing var, maybe df?\n",
        "\n",
        "# A rudimental parsing: loop to have saved incremental progress\n",
        "end_loop=math.ceil(len(entities)/500)"
      ],
      "metadata": {
        "id": "wj43oxNLu-Om"
      },
      "id": "wj43oxNLu-Om",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking `genderize.py` ---> Reproducibility: **6/10** needs deps only, .env inclusion of sensitive data, if someone wants to reproduce it needs to load his Genderize `API_KEY`, else the code will draw from Jacopo's"
      ],
      "metadata": {
        "id": "pp_6BGkHvQ8S"
      },
      "id": "pp_6BGkHvQ8S"
    },
    {
      "cell_type": "code",
      "source": [
        "path=db+'/BankersMM/Data/gender_from_names/'\n",
        "# this repo is not available"
      ],
      "metadata": {
        "id": "WP8qxIkRvYhK"
      },
      "id": "WP8qxIkRvYhK",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking `gpt_education.py` ---> Reproducibility: **4/10**, .env inclusion of sensitive data, if someone wants to reproduce it needs to load his OpenAI `API_KEY`, else the code will draw from Jacopo's. When dealing with transformer cleaning reproducibility is a major issue --> not granted"
      ],
      "metadata": {
        "id": "cI8FNmN7wI7M"
      },
      "id": "cI8FNmN7wI7M"
    },
    {
      "cell_type": "code",
      "source": [
        "root=\"C:/Users/jacop/\"\n",
        "path=\"Dropbox/LinkedIn profiling/clean/\" # --> same dir adjustments as above path = './clean'"
      ],
      "metadata": {
        "id": "b0JggpzuwB59"
      },
      "id": "b0JggpzuwB59",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file=root+path+\"education/education_cleaned_postmanual_v3.csv\"\n",
        "\n",
        "df=pd.read_csv(file)\n",
        "df[\"degree\"] = df[\"degree\"].str.replace(\"|\", \"&AND\")\n",
        "df[\"degree\"] = df[\"degree\"].str.replace(\"-\", \"&!AND\")\n",
        "degrees = df['degree'].dropna().drop_duplicates().reset_index(drop=True)\n",
        "schools = df['schoolname_original'].dropna().drop_duplicates().reset_index(drop=True)\n",
        "# Define combined string length\n",
        "bulked=1\n",
        "#Set up output dataframe\n",
        "areas = pd.DataFrame(columns=['area_gpt', 'degree'])\n",
        "\n",
        "\n",
        "query=\"classify into areas and level of studies. Only one area and one level, no more.\"\n",
        "query=query+\"Areas: Business and Finance and Economics; Law; Arts and Humanities; Sciences Engineering and Technology;. If do not fit into these, print Other.\"\n",
        "query=query+\"Levels: High School; Exchange Program; Undergraduate; Graduate; Professional; If do not fit into these, print Other.\";\n",
        "query=query+\" for each degree, the output must be as follows: area - level (e.g. Business and Finance and Economics - Undergraduate).\"\n",
        "query=query+\" Never print more than one combination area - degree (i.e. the output only has one - symbol)\"\n",
        "query = query+\" Only print final output.\"\n",
        "\n",
        "iterations=math.ceil(len(degrees)/bulked)\n",
        "\n",
        "for x in tqdm(range(0,iterations), desc=\"queries completed: \"):\n",
        "\n",
        "    # Set up the string\n",
        "    degree_string = degrees[x]\n",
        "\n",
        "    # Set up query\n",
        "    client = OpenAI(\n",
        "      api_key=apikey\n",
        "    )\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "      model=\"gpt-4o-mini\",\n",
        "      store=True,\n",
        "      messages=[\n",
        "        {\"role\": \"user\", \"content\": \"from this degree (| separates degree): \"+degree_string+query}\n",
        "      ]\n",
        "    )\n",
        "\n",
        "    content=completion.choices[0].message.content\n",
        "    degree=degree_string\n",
        "    areas = pd.concat([areas, pd.DataFrame({'area_gpt': [content], 'degree': [degree]})], ignore_index=True)\n",
        "\n",
        "areas.to_csv(outfile+\".csv\")\n",
        "\n",
        "#areas=areas_bkcp --> not sure what these are for, will break the code\n",
        "#areas_bkcp=areas\n",
        "areas[\"area_gpt\"] = areas[\"area_gpt\"].str.replace(\"\\n\", ' | ')\n",
        "# Rerrange the output and extract\n",
        "\n",
        "flags = [0] * bulked  # Initialize flag vector with 0s --> actually just [0], see line 10: bulked = 1 and never updated\n",
        "\n",
        "outdf=pd.DataFrame(columns=['degree', 'area_gpt', 'level_gpt'])"
      ],
      "metadata": {
        "id": "k9fELjgOwh2Y"
      },
      "id": "k9fELjgOwh2Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Checking `gpt_jobs.py` ---> Reproducibility: **4/10**, .env inclusion of sensitive data, if someone wants to reproduce it needs to load his OpenAI `API_KEY`, else the code will draw from Jacopo's. When dealing with transformer cleaning reproducibility is a major issue --> not granted (same approach as the one above)\n",
        "\n"
      ],
      "metadata": {
        "id": "8FxQlzHmyHfZ"
      },
      "id": "8FxQlzHmyHfZ"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ADgZ6pAyL9W"
      },
      "id": "2ADgZ6pAyL9W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking `jobs.py` ---> Reproducibility: **8/10**, needs minor adjustments in the directories and in terms of cleaner-code, but can be reproduced."
      ],
      "metadata": {
        "id": "ZbIcJsVIye1y"
      },
      "id": "ZbIcJsVIye1y"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5q8RbZW_y67y"
      },
      "id": "5q8RbZW_y67y",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nlp_a",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
